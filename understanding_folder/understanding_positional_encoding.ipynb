{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0290, 0.4019, 0.2598, 0.3666, 0.0583, 0.7006, 0.0518, 0.4681],\n",
       "         [0.6738, 0.3315, 0.7837, 0.5631, 0.7749, 0.8208, 0.2793, 0.6817],\n",
       "         [0.2837, 0.6567, 0.2388, 0.7313, 0.6012, 0.3043, 0.2548, 0.6294],\n",
       "         [0.9665, 0.7399, 0.4517, 0.4757, 0.7842, 0.1525, 0.6662, 0.3343]],\n",
       "\n",
       "        [[0.7893, 0.3216, 0.5247, 0.6688, 0.8436, 0.4265, 0.9561, 0.0770],\n",
       "         [0.4108, 0.0014, 0.5414, 0.6419, 0.2976, 0.7077, 0.4189, 0.0655],\n",
       "         [0.8839, 0.8083, 0.7528, 0.8988, 0.6839, 0.7658, 0.9149, 0.3993],\n",
       "         [0.1100, 0.2541, 0.4333, 0.4451, 0.4966, 0.7865, 0.6604, 0.1303]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "seq_len = 4\n",
    "d_model = 8\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "input_embeddings = torch.rand(batch_size, seq_len, d_model) \n",
    "input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = torch.zeros(seq_len, d_model)\n",
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [1.],\n",
       "        [2.],\n",
       "        [3.]], dtype=torch.float16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position = torch.arange(0, seq_len, dtype = torch.float16).unsqueeze(1)\n",
    "position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_19120\\1762276638.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  div_term = (1 / torch.tensor(10000 ** (position / d_model)))\n"
     ]
    }
   ],
   "source": [
    "div_term = (1 / torch.tensor(10000 ** (position / d_model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000],\n",
       "        [0.3110, 0.9502, 0.3110, 0.9502, 0.3110, 0.9502, 0.3110, 0.9502],\n",
       "        [0.1986, 0.9800, 0.1986, 0.9800, 0.1986, 0.9800, 0.1986, 0.9800],\n",
       "        [0.0947, 0.9956, 0.0947, 0.9956, 0.0947, 0.9956, 0.0947, 0.9956]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Odd Position\n",
    "pe[:, 0::2] = torch.sin(position * div_term)\n",
    "pe[:, 1::2] = torch.cos(position * div_term)\n",
    "pe # (seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000, 1.0000],\n",
       "         [0.3110, 0.9502, 0.3110, 0.9502, 0.3110, 0.9502, 0.3110, 0.9502],\n",
       "         [0.1986, 0.9800, 0.1986, 0.9800, 0.1986, 0.9800, 0.1986, 0.9800],\n",
       "         [0.0947, 0.9956, 0.0947, 0.9956, 0.0947, 0.9956, 0.0947, 0.9956]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = pe.unsqueeze(0) # (1, seq_len, d_model)\n",
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0290, 1.4019, 0.2598, 1.3666, 0.0583, 1.7006, 0.0518, 1.4681],\n",
      "         [0.9848, 1.2817, 1.0947, 1.5133, 1.0859, 1.7710, 0.5903, 1.6319],\n",
      "         [0.4823, 1.6367, 0.4374, 1.7113, 0.7998, 1.2843, 0.4534, 1.6093],\n",
      "         [1.0612, 1.7356, 0.5464, 1.4713, 0.8789, 1.1481, 0.7610, 1.3299]],\n",
      "\n",
      "        [[0.7893, 1.3216, 0.5247, 1.6688, 0.8436, 1.4265, 0.9561, 1.0770],\n",
      "         [0.7218, 0.9516, 0.8525, 1.5921, 0.6086, 1.6579, 0.7300, 1.0157],\n",
      "         [1.0825, 1.7883, 0.9514, 1.8788, 0.8825, 1.7458, 1.1135, 1.3792],\n",
      "         [0.2048, 1.2497, 0.5280, 1.4407, 0.5913, 1.7821, 0.7551, 1.1259]]])\n"
     ]
    }
   ],
   "source": [
    "print(input_embeddings + pe[:, :input_embeddings.shape[1], :].requires_grad_(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zero_to_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
