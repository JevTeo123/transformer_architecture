{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1117, -0.4966,  0.1631],\n",
       "         [-0.8817,  0.0539,  0.6684],\n",
       "         [-0.0597, -0.4675, -0.2153],\n",
       "         [ 0.8840, -0.7584, -0.3689],\n",
       "         [-0.3424, -1.4020,  1.4255]],\n",
       "\n",
       "        [[ 0.7987, -1.4949,  0.8810],\n",
       "         [-1.1786, -0.9340, -0.5675],\n",
       "         [-0.2772, -0.4030,  0.4195],\n",
       "         [ 0.9380,  0.0078, -0.3139],\n",
       "         [-1.1567,  1.8409, -1.0174]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1234)\n",
    "batch_size = 2\n",
    "seq_len = 5\n",
    "d_model = 3\n",
    "vocab_size = 10\n",
    "\n",
    "matrix = torch.randn(batch_size, seq_len, d_model)\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.2428e-01, -1.8699e-01,  5.2938e-01,  1.0465e-01, -5.7336e-01,\n",
       "           1.6727e-01,  2.6760e-01, -2.7299e-01, -3.8827e-02, -4.7621e-02],\n",
       "         [-5.7019e-01, -2.4984e-01,  8.5525e-01,  5.0524e-01, -6.9976e-01,\n",
       "          -1.4732e-01,  3.7307e-01, -6.4307e-01, -2.3726e-01,  5.9199e-01],\n",
       "         [ 2.4555e-01, -2.3330e-01,  3.9669e-01, -1.7843e-02, -6.2004e-01,\n",
       "           2.3836e-01,  2.0575e-01, -8.5151e-02,  9.9018e-03, -2.4301e-01],\n",
       "         [ 7.4344e-01, -7.2891e-02,  6.9520e-04, -4.3702e-01, -3.7343e-01,\n",
       "           5.2457e-01,  4.1697e-01, -8.9663e-02,  1.0043e-01, -5.6253e-01],\n",
       "         [ 1.3323e-01, -6.9692e-02,  1.2489e+00,  6.3638e-01, -4.6369e-01,\n",
       "          -3.0055e-02, -6.0520e-03, -4.7950e-01, -2.2608e-02,  1.6765e-01]],\n",
       "\n",
       "        [[ 7.1152e-01,  7.7581e-02,  5.9605e-01,  7.0271e-03, -2.1624e-01,\n",
       "           3.5518e-01,  2.9913e-01, -4.1051e-01,  8.1647e-02, -2.7374e-01],\n",
       "         [ 2.5855e-01, -5.3098e-01,  9.7713e-01,  4.4182e-01, -1.0311e+00,\n",
       "           3.8014e-02, -6.4438e-01,  6.3229e-01,  1.5995e-01, -5.9966e-01],\n",
       "         [-5.8897e-02, -1.7867e-01,  6.4582e-01,  2.3130e-01, -5.7668e-01,\n",
       "           7.8002e-02,  3.1585e-01, -4.2434e-01, -9.7469e-02,  1.5724e-01],\n",
       "         [ 3.3382e-01, -2.9164e-02, -2.4730e-01, -5.3965e-01, -3.2052e-01,\n",
       "           4.7809e-01,  8.8677e-01, -5.1946e-01, -7.7078e-02, -1.1844e-01],\n",
       "         [-1.0720e+00, -5.0752e-01, -8.8935e-03, -1.8106e-02, -1.0002e+00,\n",
       "          -7.2541e-02,  8.0671e-01, -5.1042e-01, -3.8928e-01,  6.6744e-01]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This multiplies the randomly initialized weights with each token in the matrix and \n",
    "# adds the bias to get vocab size \n",
    "proj = nn.Linear(d_model, vocab_size)\n",
    "proj(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.2270, -2.5383, -1.8219, -2.2466, -2.9246, -2.1840, -2.0837,\n",
       "          -2.6243, -2.3901, -2.3989],\n",
       "         [-2.9939, -2.6736, -1.5685, -1.9185, -3.1235, -2.5710, -2.0506,\n",
       "          -3.0668, -2.6610, -1.8317],\n",
       "         [-2.0854, -2.5642, -1.9342, -2.3488, -2.9510, -2.0926, -2.1252,\n",
       "          -2.4161, -2.3210, -2.5739],\n",
       "         [-1.6693, -2.4856, -2.4121, -2.8498, -2.7862, -1.8882, -1.9958,\n",
       "          -2.5024, -2.3123, -2.9753],\n",
       "         [-2.4181, -2.6210, -1.3024, -1.9149, -3.0150, -2.5814, -2.5574,\n",
       "          -3.0308, -2.5739, -2.3837]],\n",
       "\n",
       "        [[-1.7758, -2.4098, -1.8913, -2.4803, -2.7036, -2.1322, -2.1882,\n",
       "          -2.8979, -2.4057, -2.7611],\n",
       "         [-2.1942, -2.9837, -1.4756, -2.0109, -3.4838, -2.4147, -3.0971,\n",
       "          -1.8205, -2.2928, -3.0524],\n",
       "         [-2.4285, -2.5482, -1.7238, -2.1383, -2.9463, -2.2916, -2.0537,\n",
       "          -2.7939, -2.4670, -2.2123],\n",
       "         [-2.0555, -2.4185, -2.6367, -2.9290, -2.7099, -1.9113, -1.5026,\n",
       "          -2.9088, -2.4664, -2.5078],\n",
       "         [-3.3424, -2.7779, -2.2793, -2.2885, -3.2705, -2.3429, -1.4637,\n",
       "          -2.7808, -2.6596, -1.6029]]], grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log_softmax(proj(matrix), dim = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zero_to_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
